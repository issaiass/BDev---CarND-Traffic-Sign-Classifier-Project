{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5f61fe",
   "metadata": {},
   "source": [
    "# Traffic Sign Classifier Project\n",
    "\n",
    "In this example we will go through several paths of building ConvNets in Tensorflow 2.0 to build a traffic sign classifier.\n",
    "\n",
    "This traffic sign classifier will use Deep Neural Networks, we will start by using a custom shallow neural network to test the classifier.\n",
    "\n",
    "On the second stage we will build the same neural network using a dropout layer and finally in the third step we will build a neural network based on transfer learning.\n",
    "\n",
    "Finally, after comparing the model we will see which one is the best by evaluating the metrics result.  Finally after the notebook is completed we will deploy the model into a heroku app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dda5af",
   "metadata": {},
   "source": [
    "### We will first import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13dfe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import RandomTranslation, RandomContrast\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation, RandomZoom \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import MobileNetV2, Xception, ResNet50V2\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import asarray\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import itertools\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb638cc6",
   "metadata": {},
   "source": [
    "### Then we will specify the folders that will be needed in the process\n",
    "\n",
    "Train will contain the images that will be used to modelate the classifier\n",
    "Test will be used to demonstrate the performance of the classifier\n",
    "\n",
    "All other csv files contains general information of the dataset, this dataset is labeled to be used as a benchmark for image classification.  The files contain the region of interest in format *(w, h, x1, y1, x2, y2, classId, image_path)*. Because we will be using the images in the classification pipeline, we do not have the need to use more than the *classId* and the *image_path*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887868a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "train_path    = 'Train'\n",
    "test_path     = 'Test'\n",
    "\n",
    "# data frames\n",
    "training_data = 'Train.csv'\n",
    "testing_data  = 'Test.csv'\n",
    "label_names   = 'signnames.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669e337",
   "metadata": {},
   "source": [
    "Now we will explore the datasets mentioned on the previous markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3deed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(training_data)\n",
    "test_df = pd.read_csv(testing_data)\n",
    "class_df = pd.read_csv(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac97f3d",
   "metadata": {},
   "source": [
    "As you will see in the next step we will only need to pop out the classId and the path of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f519bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a1351",
   "metadata": {},
   "source": [
    "We will have now general insights of the statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9431cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88889f",
   "metadata": {},
   "source": [
    "Our dataset has basically 39209 labeled images, all classes are from 0-42 corresponding to 43 labels and near 50% of the dataset is the label 12.  Just for curiosity, let's check the test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3671f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7050b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1796da0",
   "metadata": {},
   "source": [
    "As you saw above, we have a very good label for each target, so no need to worry about it, we can get out the name of the label give the value or location of the sign name.\n",
    "\n",
    "For example, we could see that the last column is the name of the sign name related to the class Id, but we could follow the index of the dataframe to evaluate the classId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a939f",
   "metadata": {},
   "source": [
    "### Visual Insights\n",
    "\n",
    "We will build a simple insight of the dataset for check if the dataset is imbalanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.style.use('ggplot') # change graph style\n",
    "plt.figure(figsize=(8,8))      # change figure size\n",
    "\n",
    "classes = train_df['ClassId']  # get the classes of the dataframe\n",
    "res = classes.value_counts().sort_index()\n",
    "res.plot(kind='bar', alpha=0.75, rot=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88801f1",
   "metadata": {},
   "source": [
    "So our dataset is imbalanced, no problem.  There are methods for combat imbalanced datasets but currently we will not cover that part, we will only focus on the task of classification.\n",
    "\n",
    "Below you will se some hyperparameters like the image batch sizes and the height and width properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a182e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42                        # random seed to maintain the results\n",
    "validation_split = 0.2           # percentage of the validation dataset\n",
    "np.random.seed(seed)             # maitain same results\n",
    "batch_size = 64                  # we will process each 64 image of dataset time by time until you complete the full dataset\n",
    "img_width, img_height = 128, 128 # the size of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b6cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training dataset \n",
    "train_ds = image_dataset_from_directory(train_path,\n",
    "                                       validation_split=validation_split,\n",
    "                                       subset='training',\n",
    "                                       seed=seed,\n",
    "                                       image_size=(img_width, img_height),\n",
    "                                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the validation dataset\n",
    "val_ds = image_dataset_from_directory(train_path,\n",
    "                                       validation_split=validation_split,\n",
    "                                       subset='validation',\n",
    "                                       seed=42,\n",
    "                                       image_size=(img_width, img_height),\n",
    "                                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586227ad",
   "metadata": {},
   "source": [
    "Another way to load images is using the *ImageDataGenerator()*  An example is below:\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, shear_angle=0.2, zoom_range=0.2, horizontal_flip=False)\n",
    "\n",
    "One thing to note is that all the transformations will be done to the training but not for the test set.\n",
    "The other thing is that we could not us the horizontal flip because probably are traffic signals to move in one direction or another.\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "Now we can use the data generator as follows:\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        'Train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "        \n",
    "    train_generator = test_datagen.flow_from_directory(\n",
    "        'Test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87645fd",
   "metadata": {},
   "source": [
    "### Exploratory Visualization of the Dataset\n",
    "\n",
    "Now we will use the basics of matplotlib to explore the dataset.  Please take in consideration that *train_ds* and *valid_ds* have to outputs, of tf.data.Dataset and it has two tensors, the first one is for the images and the second one is for the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72488a3a",
   "metadata": {},
   "source": [
    "Before starting, for easy understanding, we must match the output of the dataset with the output of the ground truth values, just formatting only, if you print the first lines of the *train_ds.class_names* and *class_names* dict you will find why doesn't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[v for v in class_df['ClassId']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4462dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df['ClassId'] = np.array(train_ds.class_names,dtype='int')\n",
    "class_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51d918",
   "metadata": {},
   "source": [
    "The first thing to note is the type, it is a string and we have integers.  The second one is the name also doesn't match, cases 0 and 1 are ok, but when it comes to 2, 3 and so on for class_names dictionary it will fail to match.  To eliminate this problem and cause confusion we will rematch the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974c89f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_dataset(dataset, target_names, **dataviz_args):\n",
    "    \"\"\" Visualization of the dataset given the dictionary of target names\n",
    "    \n",
    "    Input:\n",
    "    dataset: tf.data.Dataset. A tensorflow dataset containing the images to plot\n",
    "    target_names: dictionary.  The dictionary contains integer keys and string values.\n",
    "    **dataviz: dictionary.  Contains the arguments necessary to plot the data\n",
    "        - nrows. int. Total number of rows to display\n",
    "        - ncols.  int. Total number of columns to display\n",
    "        - figsize. int. Size of images to plot\n",
    "        - hspace. int. Vertical space between images\n",
    "        - wspace. int. Horizontal space between images\n",
    "        - title_size. int.  Title of the images\n",
    "       \n",
    "    Output:\n",
    "    None: None.\n",
    "    \n",
    "    NOTE:  Plot the images in the way you want to show\n",
    "    \"\"\"\n",
    "    # configuration parameters\n",
    "    figsize = dataviz_args['figsize']\n",
    "    hspace = dataviz_args['hspace']\n",
    "    wspace = dataviz_args['wspace']\n",
    "    nrows = dataviz_args['nrows']\n",
    "    ncols = dataviz_args['ncols']\n",
    "    size = dataviz_args['title_size']\n",
    "    total = nrows*ncols # totalo of images \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.suptitle('Dataset Visualization', size=size) # change title description\n",
    "    plt.subplots_adjust(hspace=hspace, wspace=wspace) # adjust plot spacing\n",
    "    for images, labels in dataset.take(1):   # take 1 image and 1 label randomlhy\n",
    "        for i in range(total):               # for all images\n",
    "            img = images[i].numpy().astype(\"uint8\") # transform to a numpy array\n",
    "            label = int(labels[i])                  # get the label strin into a number\n",
    "            label = target_names.iloc[label].ClassId  # translate to the correct class\n",
    "            label_name = target_names.iloc[label].SignName # translate to te correct label name\n",
    "            plt.subplot(nrows, ncols, i + 1) # prepare to plot\n",
    "            plt.imshow(img) # plot the image\n",
    "            plt.title(\"Label {}\\n{}\".format(label, label_name)) # print the label and label name\n",
    "            plt.axis(\"off\") # shut down the axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the dataset\n",
    "viz_args = dict(nrows=3, ncols=3, figsize=(8,8), hspace=0.7, wspace=1, title_size=20)\n",
    "visualize_dataset(train_ds, target_names=class_df, **viz_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08524e",
   "metadata": {},
   "source": [
    "#### Performance of the Dataset\n",
    "\n",
    "The next step is to ensure we are using correctly the buffer of the PC, Tensorflow provides some functions to have data in memory without affecting the performance and block.\n",
    "\n",
    "*Dataset.cache()* keeps images in memory after loaded during the first epoch and ensures it will not causes problems on the training process.\n",
    "\n",
    "*Dataset.prefetch()* makes an overlap of the data preprocessing and model excecution while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotune the dataset, make a cache of image files, shuffle it and make overlap of the data in memory\n",
    "AUTOTUNE = tf.data.AUTOTUNE \n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE) \n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac90b2",
   "metadata": {},
   "source": [
    "#### Standarization of the data\n",
    "\n",
    "Data standarization means in the case of images that our images are values between [0, 255], for neural networks is preffered to have the dataset in terms of [0, 1], why? because it helps the model training to act fast.  \n",
    "\n",
    "*Rescaling* will do the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a83988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data between 0 and 1\n",
    "normalization_layer = Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it will get the first image of the dataset\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "# Notice that is a batch of images\n",
    "print(image_batch.shape)\n",
    "# Notice the shape of the tensor, that is, one image.\n",
    "print(first_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape, num_classes=1, learning_rate=0.001):\n",
    "    \"\"\" Construct the model before train\n",
    "    \n",
    "    Input:\n",
    "    input_shape: tf.Tensor. A tensorflow tensor containing the image in the shape (w,h,3)\n",
    "    num_classes: int.  Total classes to classify.\n",
    "    learning_rate: float32.  Hyperparameter for Adam\n",
    "       \n",
    "    Output:\n",
    "    model: keras.engine.sequential.Sequential.  The constructed model and compiled\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Rescaling(1./255, input_shape=input_shape, name='rescaling'),      # rescale the image between [0, 1]\n",
    "        Conv2D(16, 3, padding='same', activation='relu', name='conv2d_1'), # 16 convs of 3x3 kernels\n",
    "        MaxPooling2D(name='maxpool2d_1'),                                  # do maxpooling 2x2\n",
    "        Conv2D(32, 3, padding='same', activation='relu', name='conv2d_2'), # 32 convs of 3x3 kernels\n",
    "        MaxPooling2D(name='maxpool2d_2'),                                  # do maxpooling 2x2\n",
    "        Conv2D(64, 3, padding='same', activation='relu', name='conv2d_3'), # 64 convs of 3x3 kernels\n",
    "        MaxPooling2D(name='maxpool2d_3'),                                  # do maxpooling 2x2\n",
    "        Flatten(name='flatten'),                                           # flatten\n",
    "        Dense(128, activation='relu', name='dense'),                       # 128 by relu activation\n",
    "        Dense(num_classes, name='preds')                                   # total classes will be the softmax output\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, name='adam')             # use adam optimizer\n",
    "    loss = SparseCategoricalCrossentropy(from_logits=True)                 # multiclass classification\n",
    "    metrics=['accuracy']                                                   # metrics\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)         # compile the model\n",
    "    return model                                                           # return that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd90300",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_shape = first_image.shape # input shape is (w, h, 3)\n",
    "num_classes = len(class_df) # calculate the total classes of the dataset, a total of 43\n",
    "learning_rate = 0.001          # how fast will act the optimizer (Adam)\n",
    "\n",
    "# make the model\n",
    "model1 = define_model(input_shape, num_classes, learning_rate)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcffc5d",
   "metadata": {},
   "source": [
    "#### A better visualization of the model architecture\n",
    "\n",
    "We provide to you a better way to visualize the model, also it shows you a best way to analize graphically and also include on your paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU MUST INSTALL pydot and GraphViz for this to work\n",
    "imgpath = './images/naive_model1.png'\n",
    "plot_model(model1, to_file=imgpath)\n",
    "#img = load_img(imgpath)\n",
    "#plt.imshow(img)\n",
    "#plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e75bf22",
   "metadata": {},
   "source": [
    "We present here a way to train a model using the type *tf.data.Dataset*, but given straight data you could use the *fit* method in several ways.  I will also like to make callbacks to do early stopping if the model starts to overfit or save the model using the checkpointer, belw is an example.  More information on the [save and load tutorials](https://www.tensorflow.org/tutorials/keras/save_and_load)\n",
    "\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "                                                 \n",
    "    model.fit(train_images, \n",
    "              train_labels,  \n",
    "              epochs=10,\n",
    "              validation_data=(test_images, test_labels),\n",
    "              callbacks=[cp_callback, earlystop]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1473a",
   "metadata": {},
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "    checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5549a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(train_ds, valid_ds, **kwargs):\n",
    "    \"\"\" Trains a model given the datasets of train an validation\n",
    "    \n",
    "    Input:\n",
    "    train_ds: tf.data.Dataset. Instances of training images and labels\n",
    "    valid_ds: tf.data.Dataset. Instances of validation images and labels\n",
    "    kwargs: dict.  Contains other parameters of configuration\n",
    "        - model.  tf.keras.engine.sequential.Sequential.  A model in the sequential format\n",
    "        - epochs. int. the number of max epocs to train\n",
    "        - checkpoint_path. string. Path to save the model weights\n",
    "       \n",
    "    Output:\n",
    "    model: tf.keras.callbacks.History.  The result of the training log\n",
    "    \"\"\"\n",
    "    # get the parameters\n",
    "    model = kwargs['model']\n",
    "    epochs = kwargs['epochs']\n",
    "    filepath = kwargs['checkpoint_path']\n",
    "    save_freq = kwargs['save_freq']\n",
    "    \n",
    "    # configure callbacks\n",
    "    early_stop  = EarlyStopping(monitor='loss', patience=3)\n",
    "    cp_callback = ModelCheckpoint(filepath=filepath, save_weights_only=True, save_freq=save_freq, verbose=2)\n",
    "    callbacks = [cp_callback, early_stop]\n",
    "    \n",
    "    # train the model\n",
    "    history = model.fit(train_ds, validation_data=valid_ds, epochs=epochs, callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36482c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the total epochs to train the model and configure the path to save the weights\n",
    "epochs = 25\n",
    "checkpoint_path = '.checkpoint/naive/model'\n",
    "save_freq = 5*batch_size\n",
    "train_args = dict(model=model1, epochs=epochs, checkpoint_path=checkpoint_path, save_freq=save_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aefcde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = train_model(train_ds, val_ds, **train_args) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(H, epochs, imgpath=None):\n",
    "    \"\"\" Trains a model given the datasets of train an validation\n",
    "    \n",
    "    Input:\n",
    "    train_ds: tf.data.Dataset. Instances of training images and labels\n",
    "    valid_ds: tf.data.Dataset. Instances of validation images and labels\n",
    "    kwargs: dict.  Contains other parameters of configuration\n",
    "        - model.  tf.keras.engine.sequential.Sequential.  A model in the sequential format\n",
    "        - epochs. int. the number of max epocs to train\n",
    "        - checkpoint_path. string. Path to save the model weights\n",
    "       \n",
    "    Output:\n",
    "    model: tf.keras.callbacks.History.  The result of the training log\n",
    "    \"\"\"\n",
    "    \n",
    "    # accuracy and validation accuracy\n",
    "    acc = H.history['accuracy']\n",
    "    val_acc = H.history['val_accuracy']\n",
    "\n",
    "    # loss and validation loss\n",
    "    loss = H.history['loss']\n",
    "    val_loss = H.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    # plot training and validation accuracy and loss, finally save\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle('Model Training Results', size=20)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Epoch no.')\n",
    "    plt.ylabel('Accuracy')    \n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Epoch no.')\n",
    "    plt.ylabel('Loss')    \n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.savefig(imgpath) if imgpath is not None else _    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch = len(history1.epoch)\n",
    "plot_path = './images/training_naive_model1'\n",
    "plot_results(history1, plot_epoch, plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e489f5d",
   "metadata": {},
   "source": [
    "#### Inputs and Ouputs format\n",
    "\n",
    "If you ask, the input and outputs format is very important to make, in this cas a classification.  Bad format will make the code to not run or crash. Below you will see the types expected from the input and the output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8526b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5876c8d",
   "metadata": {},
   "source": [
    "#### Plot Prediction Results\n",
    "\n",
    "Lets plot the prediction results.  As you see above we need an impot tensor of (1, 128, 128, 3), so we have to load the test images from the path, convert to an array and expand its dimentions to the batch to predict, currently only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(test_df, target_names, model, imgpath=None):\n",
    "    \"\"\" Trains a model given the datasets of train an validation\n",
    "    \n",
    "    Input:\n",
    "    test_df: pd.DataFrame. A test dataframe corresponding to the current images and labels\n",
    "    target_names: pd.DataFrame. The dataframe corresponding to the current classes\n",
    "    model: keras.engine.sequential.Sequential.  A model corresponding of the current neural net  \n",
    "    nimages: int. Number of images to display\n",
    "    imgpath: \n",
    "       \n",
    "    Output:\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ntest = len(test_df)\n",
    "    rand_ix = np.random.randint(ntest)\n",
    "    test_path = test_df['Path'][rand_ix]\n",
    "    test_label = int(test_df['ClassId'][rand_ix]) \n",
    "    img = load_img(test_path, target_size=(img_height, img_width))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "    pred = model.predict(img_array)\n",
    "    score = tf.nn.softmax(pred[0])\n",
    "    acc = np.round(100*np.max(score),2)\n",
    "    pred_label = np.argmax(score)\n",
    "    pred_label = target_names.iloc[pred_label].ClassId\n",
    "    pred_name = target_names.iloc[pred_label].SignName        \n",
    "        \n",
    "    plt.title('Label {}\\nPrediction {}\\n{}\\n{}%'.format(test_label, pred_label, pred_name, acc))\n",
    "    plt.imshow(img);\n",
    "    plt.axis(\"off\");\n",
    "    plt.savefig(imgpath) if imgpath is not None else _ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c78cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(test_df, target_names, model, imgpath=None):\n",
    "    \"\"\" Trains a model given the datasets of train an validation\n",
    "    \n",
    "    Input:\n",
    "    test_df: pd.DataFrame. A test dataframe corresponding to the current images and labels\n",
    "    target_names: pd.DataFrame. The dataframe corresponding to the current classes\n",
    "    model: keras.engine.sequential.Sequential.  A model corresponding of the current neural net  \n",
    "    nimages: int. Number of images to display\n",
    "    imgpath: \n",
    "       \n",
    "    Output:\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ntest = len(test_df)\n",
    "    test_labels = []\n",
    "    pred_labels = []\n",
    "    pred_acc = []\n",
    "    for i in range(9):\n",
    "        rand_ix = np.random.randint(ntest)\n",
    "        test_path = test_df['Path'][rand_ix]\n",
    "        test_label = int(test_df['ClassId'][rand_ix]) \n",
    "        img = load_img(test_path, target_size=(img_height, img_width))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "        pred = model.predict(img_array)\n",
    "        score = tf.nn.softmax(pred[0])\n",
    "        acc = np.round(100*np.max(score),2)\n",
    "        pred_label = np.argmax(score)\n",
    "        pred_label = target_names.iloc[pred_label].ClassId\n",
    "        pred_name = target_names.iloc[pred_label].SignName        \n",
    "        \n",
    "        test_labels.append(test_label)\n",
    "        pred_labels.append(pred_label)\n",
    "        pred_acc.append(acc)\n",
    "        \n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.title('Label {}\\nPrediction {}\\n{}\\n{}%'.format(test_label, pred_label, pred_name, acc), pad=1)\n",
    "        plt.subplots_adjust(hspace=1, wspace=2)\n",
    "        plt.imshow(img);\n",
    "        plt.axis(\"off\");\n",
    "    plt.savefig(imgpath) if imgpath is not None else _ \n",
    "    test_acc = (np.sum(pred_acc)/len(pred_acc))*(np.sum(np.array(test_labels)==np.array(pred_labels))/len(test_labels))\n",
    "    print('Test accuracy: %.3f%%' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f96259",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot 'n' predictions\n",
    "imgpath='./images/predictions_naive_model1'\n",
    "plot_predictions(test_df=test_df, target_names=class_df, model=model1, imgpath=imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1849c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topk_predictions(test_df, target_names, model, nimages=3, k=5, imgpath=None):\n",
    "    \"\"\" Plot top k predictions, will show the input image and the top predictions\n",
    "    \n",
    "    Input:\n",
    "    test_df:      pd.DataFrame. A test dataframe corresponding to the current images and labels\n",
    "    target_names: pd.DataFrame. The dataframe corresponding to the current classes\n",
    "    model: keras.engine.sequential.Sequential.  A model corresponding of the current neural net  \n",
    "    nimages: int. Number of images to plot\n",
    "    k. int. Predictions of the nimages\n",
    "    imgpath: str. path of the file to save\n",
    "       \n",
    "    Output:\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.suptitle('Top {} predictions'.format(k), size=20)\n",
    "    plt.subplots_adjust(hspace=0, wspace=0.2)\n",
    "    nrows = nimages\n",
    "    ncols = k + 1\n",
    "    ntest = len(class_df)\n",
    "    for row in range(nimages):\n",
    "        rand_ix = np.random.randint(ntest)\n",
    "        test_path = test_df['Path'][rand_ix]\n",
    "        test_label = int(test_df['ClassId'][rand_ix]) \n",
    "        img = load_img(test_path, target_size=(img_height, img_width))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "        pred = model.predict(img_array)\n",
    "        score = tf.nn.softmax(pred)\n",
    "        top5 = tf.nn.top_k(score, k=k)\n",
    "        \n",
    "        scores = list(np.round(top5.values[0]*100,2))\n",
    "        labels = list(top5.indices[0].numpy())      \n",
    "        test_name =  target_names.iloc[test_label].SignName\n",
    "        \n",
    "        curr_row = row*ncols + 1\n",
    "        plt.subplot(nrows, ncols, curr_row)\n",
    "        plt.imshow(img) \n",
    "        plt.title('Label {}\\n{}\\n'.format(test_label, test_name, pad=2))\n",
    "        plt.axis('off')\n",
    "        for c in range(ncols - 1):\n",
    "            curr_col = c + curr_row + 1\n",
    "            plt.subplot(nrows, ncols, curr_col)\n",
    "            label = labels[c]\n",
    "            label = target_names.iloc[label].ClassId\n",
    "            name = target_names.iloc[label].SignName\n",
    "            score = scores[c]\n",
    "            label_name = target_names.iloc[label].SignName\n",
    "            plt.title('{}\\n{:.2f}%\\n{}'.format(label, score, label_name))\n",
    "            plt.subplots_adjust(hspace=0.1, wspace=0.5)            \n",
    "            img = load_img('Meta/' + str(label) + '.png')            \n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "        plt.savefig(imgpath) if imgpath is not None else _ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7002321d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nimages = 3\n",
    "total_preds = 5\n",
    "imgpath = './images/topk_preds_naive_model1'\n",
    "plot_topk_predictions(test_df=test_df, target_names=class_df, model=model1, nimages=nimages, k=total_preds, imgpath=imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(test_df, target_names, model):\n",
    "    \"\"\" Prepare labels for confusion matrix\n",
    "    \n",
    "    Input:\n",
    "    test_df:      pd.DataFrame. A test dataframe corresponding to the current images and labels\n",
    "    target_names: pd.DataFrame. The dataframe corresponding to the current classes\n",
    "    model: keras.engine.sequential.Sequential.  A model corresponding of the current neural net  \n",
    "       \n",
    "    Output:\n",
    "    test_labels. list.  A list of the ground truth labels\n",
    "    test_preds. list. A list of predicted labels\n",
    "    \"\"\"\n",
    "    total = len(test_df)\n",
    "    nclass = len(target_names)\n",
    "    test_labels = []\n",
    "    pred_labels = []\n",
    "    for i in range(total):\n",
    "        rand_ix = np.random.randint(nclass)\n",
    "        test_path = test_df['Path'][rand_ix]\n",
    "        test_label = int(test_df['ClassId'][rand_ix]) \n",
    "        img = load_img(test_path, target_size=(img_height, img_width))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "        pred = model.predict(img_array)\n",
    "        score = tf.nn.softmax(pred[0])\n",
    "        pred_label = np.argmax(score)\n",
    "        pred_label = target_names.iloc[pred_label].ClassId\n",
    "        \n",
    "        test_labels.append(test_label)\n",
    "        pred_labels.append(pred_label)\n",
    "        \n",
    "    return test_labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels and predictions\n",
    "y_test, y_pred = prepare_labels(test_df=test_df, target_names=class_df, model=model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ae514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show unique labels on the test set\n",
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show unique labels of predictions\n",
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues, imgpath=None):\n",
    "    \"\"\" Plot a pretty confusion matrix\n",
    "    \n",
    "    Input:\n",
    "    cm:  array.  An array composed by a confusion matrix\n",
    "    classes: list.  A list of classes\n",
    "    title: str. The title to display of the confusion matrix\n",
    "    imgpath: str. The path to save the confusion matrix\n",
    "       \n",
    "    Output:\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=90)\n",
    "    plt.yticks(ticks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i,j], horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.grid(False)\n",
    "    plt.savefig(imgpath) if imgpath is not None else _ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare and plot the confusion matrix\n",
    "classes = [class_df.iloc[i].SignName for i in np.unique(y_pred)]\n",
    "title='Confusion Matrix'\n",
    "imgpath='./images/confusion_matrix_naive_model1'\n",
    "plot_confusion_matrix(cm, classes=classes, title=title, imgpath=imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271c32f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df097934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we cannot do horizontal flip because there are several signals that are go-left or go-right for example\n",
    "data_augmentation = Sequential(\n",
    "  [      \n",
    "    RandomRotation(0.1, input_shape=(img_height, img_width, 3)),\n",
    "    RandomZoom(0.1),\n",
    "    RandomTranslation(0.1, 0.1),\n",
    "    RandomContrast(0.1)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape, num_classes=1, learning_rate=0.001):\n",
    "    \"\"\" Construct the model before train\n",
    "    \n",
    "    Input:\n",
    "    input_shape: tf.Tensor. A tensorflow tensor containing the image in the shape (w,h,3)\n",
    "    num_classes: int.  Total classes to classify.\n",
    "    learning_rate: float32.  Hyperparameter for Adam\n",
    "       \n",
    "    Output:\n",
    "    model: keras.engine.sequential.Sequential.  The constructed model and compiled\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        data_augmentation,                                                 # do data augmentation\n",
    "        Rescaling(1./255, name='rescaling'),                               # rescale the image between [0, 1]\n",
    "        Conv2D(16, 3, padding='same', activation='relu', name='conv2d_1'), # 16 convs of 3x3 kernels\n",
    "        MaxPooling2D(name='maxpool2d_1'),                                  # do maxpooling 2x2\n",
    "        Conv2D(32, 3, padding='same', activation='relu', name='conv2d_2'), # 32 convs of 3x3 kernels\n",
    "        MaxPooling2D(name='maxpool2d_2'),                                  # do maxpooling 2x2\n",
    "        Conv2D(64, 3, padding='same', activation='relu', name='conv2d_3'), # 64 convs of 3x3 kernels\n",
    "        MaxPooling2D(name='maxpool2d_3'),                                  # do maxpooling 2x2\n",
    "        Dropout(0.1),                                                      # dropout layer with a 0.1 keep probability\n",
    "        Flatten(name='flatten'),                                           # flatten\n",
    "        Dense(128, activation='relu', name='dense'),                       # 128 by relu activation\n",
    "        Dense(num_classes, name='preds')                                   # total classes will be the softmax output\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, name='adam')             # use adam optimizer\n",
    "    loss = SparseCategoricalCrossentropy(from_logits=True)                 # multiclass classification\n",
    "    metrics=['accuracy']                                                   # metrics\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)         # compile the model\n",
    "    return model                                                           # return that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = first_image.shape # input shape is (w, h, 3)\n",
    "num_classes = len(class_df) # calculate the total classes of the dataset, a total of 43\n",
    "learning_rate = 0.001          # how fast will act the optimizer (Adam)\n",
    "\n",
    "# make the model\n",
    "model2 = define_model(input_shape, num_classes, learning_rate)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c06b22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# configure the total epochs to train the model and configure the path to save the weights\n",
    "epochs = 25\n",
    "checkpoint_path = '.checkpoint/aug_dropout/model'\n",
    "save_freq = 5*batch_size\n",
    "train_args = dict(model=model2, epochs=epochs, checkpoint_path=checkpoint_path, save_freq=save_freq)\n",
    "history2 = train_model(train_ds, val_ds, **train_args) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efa3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch = len(history2.epoch)\n",
    "plot_path = './images/aug_dropout_model'\n",
    "plot_results(history2, plot_epoch, plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab422f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 9 predictions\n",
    "imgpath='./images/aug_dropout_preds'\n",
    "plot_predictions(test_df=test_df, target_names=class_df, model=model2, imgpath=imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ab4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimages = 5\n",
    "total_preds = 5\n",
    "imgpath = './images/topk_preds_aug_dropout'\n",
    "plot_topk_predictions(test_df=test_df, target_names=class_df, model=model2, nimages=nimages, k=total_preds, imgpath=imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6257ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part will take a long time, please wait!\n",
    "\n",
    "# prepare the confusion matrix\n",
    "y_test, y_pred = prepare_labels(test_df=test_df, target_names=class_df, model=model2)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# prepare and plot the confusion matrix\n",
    "classes = [class_df.iloc[i].SignName for i in np.unique(y_pred)]\n",
    "title='Confusion Matrix'\n",
    "imgpath='./images/confusion_matrix_aug_dropout'\n",
    "plot_confusion_matrix(cm, classes=classes, title=title, imgpath=imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79084767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale pipeline\n",
    "rescale = Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2aad51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "\n",
    "input_shape = tuple(first_image.shape)\n",
    "base_model = ResNet50V2(input_tensor=Input(shape=input_shape), include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284f85e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6090b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape, num_classes=1, learning_rate=0.001):\n",
    "    \"\"\" Construct the model before train\n",
    "    \n",
    "    Input:\n",
    "    input_shape: tf.Tensor. A tensorflow tensor containing the image in the shape (w,h,3)\n",
    "    num_classes: int.  Total classes to classify.\n",
    "    learning_rate: float32.  Hyperparameter for Adam\n",
    "       \n",
    "    Output:\n",
    "    model: keras.engine.sequential.Sequential.  The constructed model and compiled\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = rescale(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    outputs = Dense(num_classes)(x)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    loss = SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metrics=['accuracy']\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1174cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = first_image.shape # input shape is (w, h, 3)\n",
    "num_classes = len(class_df) # calculate the total classes of the dataset, a total of 43\n",
    "learning_rate = 0.001          # how fast will act the optimizer (Adam)\n",
    "\n",
    "# make the model\n",
    "model3 = define_model(input_shape, num_classes, learning_rate)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe594a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# configure the total epochs to train the model and configure the path to save the weights\n",
    "epochs = 25\n",
    "checkpoint_path = '.checkpoint/transfer_learning/model'\n",
    "save_freq = 5*batch_size\n",
    "train_args = dict(model=model3, epochs=epochs, checkpoint_path=checkpoint_path, save_freq=save_freq)\n",
    "history3 = train_model(train_ds, val_ds, **train_args) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67dd2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch = len(history3.epoch)\n",
    "plot_path = './images/transfer_learning'\n",
    "plot_results(history3, plot_epoch, plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafabc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 'n' predictions\n",
    "imgpath='./images/predictions_transfer_learning'\n",
    "plot_predictions(test_df=test_df, target_names=class_df, model=model3, imgpath=imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimages = 6\n",
    "total_preds = 4\n",
    "imgpath = './images/topk_preds_transfer_learning'\n",
    "plot_topk_predictions(test_df=test_df, target_names=class_df, model=model3, nimages=nimages, k=total_preds, imgpath=imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4636ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part will take a long time, please wait!\n",
    "\n",
    "# prepare the confusion matrix\n",
    "y_test, y_pred = prepare_labels(test_df=test_df, target_names=class_df, model=model3)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# prepare and plot the confusion matrix\n",
    "classes = [class_df.iloc[i].SignName for i in np.unique(y_pred)]\n",
    "title='Confusion Matrix'\n",
    "imgpath='./images/confusion_matrix_aug_dropout'\n",
    "plot_confusion_matrix(cm, classes=classes, title=title, imgpath=imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c6c89",
   "metadata": {},
   "source": [
    "#### Saving, Loading the Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd3ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and weights path\n",
    "checkpoint_dir = '.checkpoint/best/model'\n",
    "# Save the model\n",
    "model1.save(checkpoint_dir)\n",
    "# Save the weights\n",
    "model1.save_weights(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b219725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape, num_classes=1, learning_rate=0.001):\n",
    "    \"\"\" Construct the model before train\n",
    "    \n",
    "    Input:\n",
    "    input_shape: tf.Tensor. A tensorflow tensor containing the image in the shape (w,h,3)\n",
    "    num_classes: int.  Total classes to classify.\n",
    "    learning_rate: float32.  Hyperparameter for Adam\n",
    "       \n",
    "    Output:\n",
    "    model: keras.engine.sequential.Sequential.  The constructed model and compiled\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Rescaling(1./255, input_shape=input_shape, name='rescaling'),      # rescale the image between [0, 1]\n",
    "        Conv2D(16, 3, padding='same', activation='relu', name='conv2d_1'), # 16 convs of 3x3 kernels\n",
    "        MaxPooling2D(name='maxpool2d_1'),                                  # do maxpooling 2x2\n",
    "        Conv2D(32, 3, padding='same', activation='relu', name='conv2d_2'), # 32 convs of 3x3 kernels\n",
    "        MaxPooling2D(name='maxpool2d_2'),                                  # do maxpooling 2x2\n",
    "        Conv2D(64, 3, padding='same', activation='relu', name='conv2d_3'), # 64 convs of 3x3 kernels\n",
    "        MaxPooling2D(name='maxpool2d_3'),                                  # do maxpooling 2x2\n",
    "        Flatten(name='flatten'),                                           # flatten\n",
    "        Dense(128, activation='relu', name='dense'),                       # 128 by relu activation\n",
    "        Dense(num_classes, name='preds')                                   # total classes will be the softmax output\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, name='adam')             # use adam optimizer\n",
    "    loss = SparseCategoricalCrossentropy(from_logits=True)                 # multiclass classification\n",
    "    metrics=['accuracy']                                                   # metrics\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)         # compile the model\n",
    "    return model                                                           # return that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct and define the same model architecture\n",
    "# Load the weights\n",
    "# predict\n",
    "best_model = define_model(input_shape, num_classes, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4638deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.load_weights(checkpoint_dir)\n",
    "plot_prediction(test_df=test_df, target_names=class_df, model=best_model, imgpath=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \".checkpoint/best/model-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# get the latest checkpoint\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# Restore the weights\n",
    "best_model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee76375",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_prediction(test_df=test_df, target_names=class_df, model=best_model, imgpath=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971d099",
   "metadata": {},
   "source": [
    "#### Convert a Saved Model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78396bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = np.random.rand(1, 128, 128, 3)\n",
    "        yield [data.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ce7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tflite(checkpoint_path, tflite_name, support_type=None):\n",
    "    # Convert the model\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(checkpoint_path) # path to the SavedModel directory\n",
    "    \n",
    "    if support_type == 'float':\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_dataset \n",
    "    if support_type == 'float16':\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "    if support_type == 'int8':\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_dataset        \n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "        converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    if support_type == 'int16x8a':\n",
    "        converter.representative_dataset = representative_dataset\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\n",
    "    if support_type == 'int16x8b':\n",
    "        converter.representative_dataset = representative_dataset\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8, \n",
    "                                               tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model\n",
    "    tflite_path = os.path.join(checkpoint_path, tflite_name)\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '.checkpoint/best/model'\n",
    "tflite_name = 'model.tflite'\n",
    "\n",
    "convert_tflite(checkpoint_path, tflite_name=tflite_name, support_type='int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad651bb3",
   "metadata": {},
   "source": [
    "#### Load and use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1330bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tflite_model(checkpoint_path, tflite_name):\n",
    "    # Load the TFLite model in TFLite Interpreter\n",
    "    tflite_path = os.path.join(checkpoint_path, tflite_name)\n",
    "    interpreter = tf.lite.Interpreter(tflite_path)\n",
    "    \n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "    # input details\n",
    "    print(input_details)\n",
    "    #print()\n",
    "    # output details\n",
    "    print(output_details)\n",
    "    return interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = load_tflite_model(checkpoint_path, tflite_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e220e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite_predict(test_df, interpreter):\n",
    "    rand_ix = np.random.randint(len(test_df))\n",
    "    test_path = test_df['Path'][rand_ix]\n",
    "    test_label = int(test_df['ClassId'][rand_ix]) \n",
    "    img = load_img(test_path, target_size=(img_height, img_width))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "    interpreter.set_tensor(input_details[0]['index'], img_array)\n",
    "    # run the inference\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # output_details[0]['index'] = the index which provides the input\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    #print(\"the output is {}\".format(output_data))\n",
    "    score = tf.nn.softmax(output_data)\n",
    "    #print(\"the softmax activation is {}\".format(score))\n",
    "    \n",
    "    #top_k = tf.nn.top_k(score, k=5)\n",
    "    #top_k.indices\n",
    "    #print('The top_k indices are {}'.format(top_k.indices))\n",
    "    acc = np.round(100*np.max(score),2)\n",
    "    #print('The acc is {}'.format(acc))\n",
    "    #acc_top_k = np.round(100*np.max(top_k),2)\n",
    "    #print('The top k is {}'.format(acc_top_k))    \n",
    "    pred_label = np.argmax(score)\n",
    "    pred_label = class_df.iloc[pred_label].ClassId\n",
    "    pred_name = class_df.iloc[pred_label].SignName\n",
    "    #print('The pred label is {}'.format(pred_label))\n",
    "    #print('The pred name is {}'.format(pred_name))\n",
    "    plt.title('Label {}\\nPrediction {}\\n{}\\n{}%'.format(test_label, pred_label, pred_name, acc))\n",
    "    plt.imshow(img);\n",
    "    plt.axis(\"off\");\n",
    "    plt.savefig(imgpath) if imgpath is not None else _ \n",
    "    return pred_label, pred_name, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_predict(test_df, interpreter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
